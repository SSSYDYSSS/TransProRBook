[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TransProRBook",
    "section": "",
    "text": "Preface\nThis is a side-by-side comparison of the Polars and Pandas dataframe libraries, based on Modern Pandas by Tom Augsburger.\n(In case you haven’t heard, Polars is a very fast and elegant dataframe libary that does the same kinds of things Pandas does.)\nThe bulk of this book is structured examples of idiomatic Polars and Pandas code, with commentary on the API and performance of both.\nFor the most part, I argue that Polars is “better” than Pandas, though I do try and make it clear when Polars is lacking a Pandas feature or is otherwise disappointing."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Data Source and Introduction",
    "section": "",
    "text": "2 Data Download and Processing Statement\nIn the TransPro data analysis suite, each R package (e.g., TransProR) and Python package (e.g., TransProPy) involves a vast array of mathematical algorithms, integrated machine learning techniques, and various deep learning modules. Therefore, our initial design’s focus for data selection was on the following aspects: ensuring a sufficiently large volume of data, comprehensive and diversified annotation files, balanced data distribution, and the feasibility of cross-database data integration. However, please note that to ensure the reproducibility and robustness of our technology, we ultimately chose publicly available data from TCGA and CTEX—specifically, BRCA data (large volume, publicly available, well-annotated) and SKCM data (fairly large volume, public, and balanced data distribution) as our initial data sets. We then performed a series of algorithmic explorations to uncover data features and designed visual representations of the results.\nAlthough we have batch-normalized all the data, please be aware that users can directly analyze their test data, which is acceptable. However, if you intend to merge public data from major databases, please carefully review the data processing procedures and quality control metrics of different databases in advance (for the generation of TCGA and GTEX data, please see the reference)! We recommend conducting combined analyses only under relatively similar conditions. We further suggest obtaining the original fastq files from the databases. This way, TransPro users can generate count data with uniform methods and parameters, significantly minimizing the noise caused by batch effects and enhancing the accuracy and authenticity of the results."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html#characteristics-of-the-tcga-database",
    "href": "index.html#characteristics-of-the-tcga-database",
    "title": "TransProRBook",
    "section": "Characteristics of the TCGA Database:",
    "text": "Characteristics of the TCGA Database:\n\nRich Cancer Tissue Sample Data:\n\n\nThe TCGA (The Cancer Genome Atlas) database amasses a substantial volume of tissue sample data across a variety of cancer types, encompassing multi-dimensional data such as genomics, transcriptomics, and proteomics. This repository serves as a valuable resource for cancer research, enabling researchers to delve into the biological mechanisms of cancer at multiple levels.\n\n\nPrimary Focus on Cancer Types:\n\n\nThe core objective of TCGA is to unveil the molecular mechanisms, pathogenic genes, and mutation frequencies of different cancer types through integrative analysis, thereby providing a robust scientific basis for the diagnosis, treatment, and prevention of cancer.\n\n\nLimited Quantity of Normal Tissue Samples:\n\n\nDespite the richness of cancer sample data, TCGA has a relatively limited number of normal tissue samples, which to some extent, restricts its application in comparative studies between normal and cancerous tissues."
  },
  {
    "objectID": "index.html#characteristics-of-the-gtex-database",
    "href": "index.html#characteristics-of-the-gtex-database",
    "title": "TransProRBook",
    "section": "Characteristics of the GTEx Database:",
    "text": "Characteristics of the GTEx Database:\n\nCovers Normal Tissue Sample Data from Multiple Organs and Tissues:\n\n\nThe GTEx (Genotype-Tissue Expression) database, by collecting samples from a variety of organs and tissues, offers an extensive gene expression data resource. This is crucial for understanding the heterogeneity of gene expression across different tissues and the functionality of genes under normal physiological conditions.\n\n\nFocus on Gene Expression Patterns in Normal Tissues:\n\n\nGTEx aims to reveal the patterns and variations of gene expression in normal tissues, providing a valuable foundation for researching gene functionality and regulatory mechanisms."
  },
  {
    "objectID": "index.html#demands-and-challenges-of-joint-analysis",
    "href": "index.html#demands-and-challenges-of-joint-analysis",
    "title": "TransProRBook",
    "section": "Demands and Challenges of Joint Analysis:",
    "text": "Demands and Challenges of Joint Analysis:\n\nNeed to Augment Normal Tissue Sample Volume:\n\n\nGiven the limited number of normal tissue samples in the TCGA database, it’s essential to source additional normal tissue samples from other databases like GTEx, for a more comprehensive and accurate cancer research.\n\n\nComplexity of Data Integration:\n\n\nThe joint analysis of the TCGA and GTEx databases entails data integration and standardization, requiring a meticulous and scientific approach to ensure the efficacy of data integration and the accuracy of analysis results. This may include data cleansing, standardization, and a unified analysis workflow to ensure that data obtained from different databases can be accurately and effectively combined for analysis."
  },
  {
    "objectID": "index.html#ucsc-xena-data-download",
    "href": "index.html#ucsc-xena-data-download",
    "title": "TransProRBook",
    "section": "UCSC Xena Data Download",
    "text": "UCSC Xena Data Download\n\npipline\n\n\nLog in to the official website: http://xena.ucsc.edu/\nClick “Launch Xena” to enter the main interface: https://xenabrowser.net/\nClick “DATA SETS” to enter the dataset interface: https://xenabrowser.net/datapages/\nTCGA and GTEX Data Download:\n\nGDC TCGA Breast Cancer (BRCA) (20 datasets)\n\nHTSeq - Counts (n=1,217) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=1,284) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=1,260) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGDC TCGA Melanoma (SKCM) (14 datasets)\n\nHTSeq - Counts (n=472) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=477) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=463) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGTEX\n\nTOIL RSEM expected_count (n=7,845) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nGTEX phenotype (n=9,783) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)"
  },
  {
    "objectID": "index.html#data-type",
    "href": "index.html#data-type",
    "title": "TransProRBook",
    "section": "Data Type",
    "text": "Data Type\n\ncount\nIn the context of RNA-seq data analysis, “Count” is an important concept. It represents the number of times each gene or transcript is measured in an RNA-seq experiment. Typically, these counts are obtained through sequencing machines, which measure the number of fragments associated with each gene or transcript, also known as “reads count” or “fragment count,” which indicates how many times each gene or transcript is covered or mapped in the sequencing data. These count data serve as the starting point for RNA-seq data analysis, providing raw information about the expression of genes or transcripts in different samples.\n\nUse Cases:\n\nGene Expression Analysis:\n\n\nCount data can be used to compare the relative expression levels of different genes. By tallying the counts for each gene, we can determine which genes are expressed more or less in various samples, identifying key genes.\n\n\nDifferential Expression Analysis:\n\n\nDifferential expression analysis aims to study changes in gene expression levels between different conditions or groups. In this context, count data is employed to compare gene expression levels under different conditions, often requiring statistical models to identify genes with significant differences.\n\n\nClustering Analysis:\n\n\nCount data can also be used for clustering analysis to identify groups of genes or samples with similar expression patterns. Through clustering analysis, genes with similar expression patterns can be grouped together.\n\n\nGene Annotation:\n\n\nCount data helps determine which genes or transcripts have evidence of measurement in the sequencing data, which is crucial for gene annotation.\n\n\n\nAdvantages:\n\nIntuitiveness:\n\n\nCount data is obtained directly from RNA-seq experiments, providing an intuitive and straightforward representation of gene expression.\n\n\nFlexibility:\n\n\nCount data is versatile and applicable to various RNA-seq data analysis tasks, including basic gene expression analysis and more complex differential expression analysis.\n\n\n\nDisadvantages:\n\nImpact of Sequencing Depth and Gene Length:\n\n\nCount data is influenced by sequencing depth and gene length, necessitating standardization when comparing expression levels between different samples or genes.\n\n\nZero Inflation:\n\n\nFor lowly expressed genes, count data may exhibit zero inflation, where counts are predominantly zero. Specialized statistical methods are required to address this issue.\n\n\nResource-Intensive:\n\n\nHandling raw count data can demand significant computational resources and storage space, particularly for large-scale RNA-seq datasets.\n\nIn summary, count data plays a pivotal role in RNA-seq data analysis but typically requires further standardization and analysis to derive meaningful results. It is suitable for use with RNA-seq data types, particularly for gene expression analysis and differential expression analysis.\n\n\n\nRPKM\nRPKM (Reads Per Kilobase of transcript per Million mapped reads) is a method used for quantifying gene expression. This technique overcomes two major barriers: the differences in sequencing depth between samples and the comparison of genes of different lengths. Below is a deeper analysis of the concept, calculation, and application of RPKM, as well as some of its limitations.\n\nPrinciple and Calculation of RPKM:\n\nPrinciple:\n\n\nThe RPKM method corrects the read data in sequencing experiments, making it unaffected by sequencing depth and gene length differences, thereby allowing for a more accurate comparison of gene expression levels under different conditions.\n\n\nCalculation Formula: \\[\nRPKM = \\frac{10^9 \\times C}{N \\times L}\n\\]\nWhere:\n\n\nC is the read count for a specific gene.\nN is the total number of mapped reads in the sequencing experiment.\nL is the transcript length (gene length in base pairs).\nThe \\(\\boldsymbol{10^9}\\) in the formula is a standardization factor used to adjust the units, making the results more comprehensible.\n\n\n\nApplication Scenarios:\n\nTranscriptomic Studies:\n\n\nIn transcriptome sequencing (RNA-seq), researchers often use RPKM to quantify gene expression, especially when comparing samples from different species, different tissues, or under different treatment conditions.\n\n\nQuantitative Studies of Gene Expression:\n\n\nRPKM provides a way to standardize gene expression data, allowing data obtained from different experiments or under different conditions to be compared.\n\n\n\n\nAdvantages:\n\nCorrection for Gene Length:\n\n\nRPKM takes into account the length of the genes, allowing for a fair comparison of expression levels between long and short genes, resolving the issue of read count bias. - Normalization for Sequencing Depth:\n\n\nBy standardizing the total mapped reads, RPKM allows researchers to compare data from different sequencing experiments.\n\n\nChallenges:\n\nBias in Low-Abundance Transcripts:\n\n\nRPKM may overestimate the expression levels for genes with low expression because their expression could be amplified due to statistical fluctuations or limitations in sequencing depth.\n\n\nNo Correction for Technical Variations:\n\n\nRPKM does not correct for technical biases that may occur during library preparation or sequencing, and additional statistical methods may be required to correct these biases.\n\n\nNot Suitable for Transcript Diversity:\n\n\nIf a gene has multiple isoforms, RPKM calculation may not reflect the true expression status of each transcript variant.\n\nTherefore, while RPKM is an important tool in RNA-seq data analysis, researchers need to consider its limitations when using it and consider employing other complementary methods, such as TPM (Transcripts Per Million) or more advanced quantification methods like model-based methods (e.g., DESeq2 or edgeR), which can handle differences and variations in data under different samples and conditions more effectively.\n\n\n\nFPKM\nFPKM (Fragments Per Kilobase of transcript, per Million mapped fragments) is an enhancement over RPKM, accounting for the number of sequenced fragments instead of just read counts. This modification is crucial, particularly when a single read might encompass multiple fragments due to events like “split reads” or “spliced reads” in sequencing data.\n\nFPKM Calculation:\n\nThe formula for calculating FPKM is: \\[\nFPKM = \\frac{\\text{Number of fragments mapped to a gene}}{(\\frac{\\text{Total mapped fragments}}{1,000,000}) \\times (\\frac{\\text{Length of the gene}}{1,000})}\n\\]\nWhere:\n\n\n“Fragment count of gene” refers to the number of fragments for a specific gene.\n“Gene length in kilobases” is the measurement of the gene length, using kilobases (thousands of base pairs) as the unit.\n“Total mapped fragments in millions” represents the summation of all fragments aligned with the reference genome, expressed in millions.\n\n\n\nSuitability:\nFPKM is utilized in situations similar to RPKM, primarily in RNA-seq data analysis, especially when comparing expression levels across genes or between different samples. FPKM allows a more equitable comparison of gene expression by taking into account both gene length and sequencing depth.\n\n\nAdvantages:\n\nRecognizes gene length, making it suitable for comparing expression levels across genes of diverse lengths.By normalizing per million mapped fragments, FPKM enables more fair comparisons between different samples.\n\n\n\nDisadvantages:\n\nIt may misrepresent low-abundance genes, as the total number of mapped fragments in the denominator could lead to inflated FPKM values for these genes.It doesn’t account for potential biases, such as discrepancies in sequencing depth, necessitating further adjustments.\n\n\n\nRPKM vs. FPKM:\nThough they appear similar, the necessity for FPKM in addition to RPKM comes from their unique applications and methods of calculation.\n\nDifferences:\nCalculation Basis:\n\n\nWhile RPKM normalizes gene expression levels based on read counts, gene length, and total reads, FPKM does so using fragment counts. This approach is essential for instances where a single read may correspond to multiple fragments.\n\n\nReads vs. Fragments:\n\n\nRPKM, the earlier introduced method, accounts for read counts. FPKM, an advancement over RPKM, considers fragment counts, which is vital for scenarios involving “split reads” or “spliced reads.”\n\n\nNomenclature:\n\n\nRPKM (Reads Per Kilobase of transcript, per Million mapped reads) emphasizes normalization using read counts, whereas FPKM highlights normalization based on fragment counts.\n\n\n\nWhy FPKM?\n\n\nRPKM is tailored for single-end sequencing, whereas FPKM is more applicable for paired-end RNA-seq because it takes into account that two reads can map to a single fragment, thus avoiding duplication in counting.\nFPKM is generally preferred over RPKM as it offers more precision by including fragment counts, which is particularly important for genes undergoing splicing events.\n\n\n\n\nChoosing Between RPKM and FPKM:\nWhile FPKM is generally a better choice due to its enhanced accuracy, the advent of more modern methods like TPM (Transcripts Per Million) has overshadowed both RPKM and FPKM in RNA-seq data analysis. TPM normalizes expression levels based on every million mapped transcripts and is not influenced by gene length or sequencing depth, providing a more reliable reflection of relative expression levels.\n\n\n\nTPM\nTPM (Transcripts Per Million) is an accurate method for measuring gene expression levels, capable of eliminating the effects of sequencing depth and transcript length differences between various samples.\nTo calculate TPM, we first need to obtain the normalized read counts for each transcript, which are then standardized per million transcripts. The steps are as follows:\nCalculate the read counts for each transcript, considering the effective length of the transcript (i.e., excluding the length of non-coding regions).\nCompute the ratio of each transcript’s read count to its effective length, then multiply this ratio by a normalization factor to enable comparisons between samples.\n\nTPM calculation formula is as follows:\n\\[\nTPM_i = \\left( \\frac{x_i}{l_i} \\right) \\left( \\frac{1}{\\sum_j \\frac{x_j}{l_j}} \\right) 10^6\n\\]\n\n\nWhere:\n\n\\(\\boldsymbol{x_i}\\) represents the read count of a specific transcript.\n\\(\\boldsymbol{l_i}\\) is the effective length of the transcript (in kilobases).\nSubscripts \\(\\boldsymbol{i}\\) and \\(\\boldsymbol{j}\\) denote different transcripts.\n\\(\\boldsymbol{\\sum_j \\frac{x_j}{l_j}}\\) is the sum of all transcript read counts ratios to their effective lengths.\n\n\n\nThe main differences between TPM and RPKM/FPKM:\n\nCalculation method:\n\n\nWith TPM, the expression level of each transcript is first normalized to the length of the transcript, then standardized to the total transcript expression in the sample. In contrast, RPKM/FPKM directly utilize the read counts of transcripts or fragments, normalizing based on transcript length and total read counts.\n\n\nNormalization target:\n\n\nAfter calculating TPM, the total of the TPM values for all transcripts will be 1,000,000, facilitating comparisons between different samples. The total for RPKM/FPKM is not consistent, as they are based on read counts.\n\n\nImpact of gene length:\n\n\nTPM normalizes the effect of gene length on expression level calculations by considering transcript length, making comparisons between transcripts of varying lengths more equitable. Although RPKM/FPKM also standardize based on length, they do not entirely eliminate the influence of gene length when comparing between samples.\n\n\n\nThe preference for TPM is primarily based on the following reasons:\n\nAccuracy:\n\n\nTPM more accurately reflects the actual expression levels of transcripts, without biases due to differences in sequencing depth or gene length between samples.\n\n\nComparability:\n\n\nTPM values, after standardization, allow for direct comparisons of transcript expression levels between different samples and experiments.\n\n\nUniversality:\n\n\nThe TPM calculation method is suitable for various transcriptomic studies, including gene expression quantification, differential expression analysis, and more.\n\nIn summary, while RPKM/FPKM remain useful in certain contexts, TPM is more widely accepted and utilized in modern transcriptomic analyses due to its accuracy and comparability.\n\n\n\nCPM\nCPM (Counts Per Million) is another prevalent normalization method for assessing gene or transcript expression levels, alongside other techniques such as RPKM, FPKM, and TPM. The principle behind CPM is to standardize the number of times a gene or transcript is measured (counts), allowing for the comparison of expression levels across different genes or transcripts while accounting for the total number of measurements. By normalizing each gene or transcript’s expression levels to per million measurements, CPM minimizes the impact of sequencing depth and differences between samples.\nThe calculation formula for CPM is as follows: \\[\nCPM = \\frac{\\text{Counts of gene/transcript} \\times 10^6}{\\sum (\\text{Counts of all genes/transcripts})}\n\\]\n\nWhere:\n\n“Counts of gene/transcript” refers to the number of measurements (counts) for a particular gene or transcript.\n“\\(\\boldsymbol{\\sum}\\)” represents the summation symbol, calculating the total counts for all genes or transcripts.\n\n\n\nCPM is applicable for:\n\nComparing relative expression levels of different genes or transcripts.\nComparing gene expression levels between samples, particularly when considering variations in sequencing depth and among samples.\n\n\n\nAdvantages:\n\n\nCPM is a straightforward and intuitive method of normalization, easy to understand and compute.\nIt’s suitable for comparisons between different samples, enabling a fairer assessment of gene expression differences.\n\n\n\n\nDisadvantages:\n\n\nCPM may encounter issues with lowly expressed genes because the denominator includes the total counts. For these genes, a smaller denominator might inflate the CPM value, leading to inaccuracies.\nCPM does not account for factors like gene length and sequencing depth, potentially compromising accuracy in certain scenarios.\n\n\nDespite its limitations, CPM stands as a relatively rapid and simplistic normalization technique, fitting for basic RNA-seq data analysis tasks. For instance, during differential analysis, it’s sometimes necessary to eliminate low-expression genes. Here, CPM calculations become relevant, aiding in the exclusion of these genes based on set criteria. For straightforward adjustments of counts, one can utilize the cpm() function within the edgeR package.\n\n\n\nRSEM\nHere, we delve further into the core principles and computational methods of RSEM (RNA-Seq by Expectation-Maximization). RSEM stands as a powerful tool for accurately estimating the expression levels of genes or transcripts. It is particularly proficient in handling RNA sequencing data, resolving issues of multimapping and accounting for sequence mismatches. At the heart of RSEM is the Expectation-Maximization (EM) algorithm, a statistical technique used for estimating the parameters of a probability model, especially in cases where the model involves latent variables that are not directly observable. By maximizing the log-likelihood function of the data, RSEM enables more accurate inference of the relative abundance of transcripts.\n\nThe computation process of RSEM:\n\n1.E-step (Expectation):\n\n\nUtilizing the current estimates of the parameters, RSEM calculates the expected value of each transcript being sequenced. This step takes into account the sequencing error rate and the multimapping of reads.\n\n\n2.M-step (Maximization):\n\n\nBased on the data generated in the E-step, RSEM updates the parameter estimates to maximize the likelihood of the read data.\n\nGiven the complexity of the calculations and models involved in RSEM, specialized software tools are usually employed for execution. These tools have built-in necessary mathematical models and numerical optimization methods, relieving the user from delving into the intricate details behind them.\n\n\nScope of Application:\n\n\nHigh-precision estimation of transcript abundance, suitable for complex samples with a large number of genes and transcripts, and high heterogeneity.\nQuantitative comparison of gene expression differences between different samples and studying variations between isoforms of transcripts.\n\n\n\n\nAdvantages:\n\n\nRSEM accurately handles multimapped reads, offering a more precise expression level estimate compared to traditional methods.\nThrough sophisticated statistical models, RSEM fully considers the uncertainties of reads and potential errors during the sequencing process.\n\n\n\n\nDisadvantages:\n\n\nThe RSEM calculation process is resource-intensive and time-consuming, potentially unsuitable for large-scale samples or rapid analysis workflows.\nIt requires high-quality data input and is sensitive to low-quality or highly biased data.\n\n\nIn practice, there’s an essential distinction between RSEM’s “expected_count” and the conventional raw “count.” The “expected_count” in RSEM is a statistically estimated floating-point number considering the uncertainties of read assignment, while traditional “count” is merely an integer read count based on raw sequencing data. This difference enables RSEM to provide more in-depth and accurate information on transcript abundance in certain scenarios."
  },
  {
    "objectID": "index.html#ucsc-xena-data-download-pipeline",
    "href": "index.html#ucsc-xena-data-download-pipeline",
    "title": "TransProRBook",
    "section": "UCSC Xena Data Download pipeline：",
    "text": "UCSC Xena Data Download pipeline：\n\n\nLog in to the official website: http://xena.ucsc.edu/\nClick “Launch Xena” to enter the main interface: https://xenabrowser.net/\nClick “DATA SETS” to enter the dataset interface: https://xenabrowser.net/datapages/\nTCGA and GTEX Data Download:\n\nGDC TCGA Breast Cancer (BRCA) (20 datasets)\n\nHTSeq - Counts (n=1,217) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=1,284) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=1,260) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGDC TCGA Melanoma (SKCM) (14 datasets)\n\nHTSeq - Counts (n=472) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=477) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=463) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGTEX\n\nTOIL RSEM expected_count (n=7,845) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nGTEX phenotype (n=9,783) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)"
  },
  {
    "objectID": "index.html#tcga-count-data",
    "href": "index.html#tcga-count-data",
    "title": "TransProRBook",
    "section": "TCGA Count Data",
    "text": "TCGA Count Data\n\n\nSTAR Alignment and Counting: The primary counting data in TCGA is generated by STAR, which provides gene ID, unstranded, and stranded counts data following alignment.\nMulti-dimensional Data Collection: TCGA collects many types of data including molecular characterization data for over 20,000 tumor and normal samples, contributing to the count data."
  },
  {
    "objectID": "index.html#gtex-expected-count-data",
    "href": "index.html#gtex-expected-count-data",
    "title": "TransProRBook",
    "section": "GTEx Expected Count Data",
    "text": "GTEx Expected Count Data\n\n\nPipeline Components for RNA-seq Alignment, Quantification: GTEx utilizes a pipeline for RNA-seq alignment, quantification, and quality control among other analysis tasks, which lead to the generation of expected count data.\nAlignment and Expression Quantification: GTEx RNA-seq pipeline involves alignment (STAR), QC (RNA-SeQC), and expression quantification (RSEM & RNA-SeQC) for generating expected count data.\n76-base, Paired-end Illumina TruSeq RNA Protocol: GTEx uses a 76-base, paired-end Illumina TruSeq RNA protocol, averaging around 50 million aligned reads per sample for RNA sequencing."
  },
  {
    "objectID": "intro.html#characteristics-of-the-tcga-database",
    "href": "intro.html#characteristics-of-the-tcga-database",
    "title": "1  Data Source and Introduction",
    "section": "1.1 Characteristics of the TCGA Database:",
    "text": "1.1 Characteristics of the TCGA Database:\n\nRich Cancer Tissue Sample Data:\n\n\nThe TCGA (The Cancer Genome Atlas) database amasses a substantial volume of tissue sample data across a variety of cancer types, encompassing multi-dimensional data such as genomics, transcriptomics, and proteomics. This repository serves as a valuable resource for cancer research, enabling researchers to delve into the biological mechanisms of cancer at multiple levels.\n\n\nPrimary Focus on Cancer Types:\n\n\nThe core objective of TCGA is to unveil the molecular mechanisms, pathogenic genes, and mutation frequencies of different cancer types through integrative analysis, thereby providing a robust scientific basis for the diagnosis, treatment, and prevention of cancer.\n\n\nLimited Quantity of Normal Tissue Samples:\n\n\nDespite the richness of cancer sample data, TCGA has a relatively limited number of normal tissue samples, which to some extent, restricts its application in comparative studies between normal and cancerous tissues."
  },
  {
    "objectID": "intro.html#characteristics-of-the-gtex-database",
    "href": "intro.html#characteristics-of-the-gtex-database",
    "title": "1  Data Source and Introduction",
    "section": "1.2 Characteristics of the GTEx Database:",
    "text": "1.2 Characteristics of the GTEx Database:\n\nCovers Normal Tissue Sample Data from Multiple Organs and Tissues:\n\n\nThe GTEx (Genotype-Tissue Expression) database, by collecting samples from a variety of organs and tissues, offers an extensive gene expression data resource. This is crucial for understanding the heterogeneity of gene expression across different tissues and the functionality of genes under normal physiological conditions.\n\n\nFocus on Gene Expression Patterns in Normal Tissues:\n\n\nGTEx aims to reveal the patterns and variations of gene expression in normal tissues, providing a valuable foundation for researching gene functionality and regulatory mechanisms."
  },
  {
    "objectID": "intro.html#demands-and-challenges-of-joint-analysis",
    "href": "intro.html#demands-and-challenges-of-joint-analysis",
    "title": "1  Data Source and Introduction",
    "section": "1.3 Demands and Challenges of Joint Analysis:",
    "text": "1.3 Demands and Challenges of Joint Analysis:\n\nNeed to Augment Normal Tissue Sample Volume:\n\n\nGiven the limited number of normal tissue samples in the TCGA database, it’s essential to source additional normal tissue samples from other databases like GTEx, for a more comprehensive and accurate cancer research.\n\n\nComplexity of Data Integration:\n\n\nThe joint analysis of the TCGA and GTEx databases entails data integration and standardization, requiring a meticulous and scientific approach to ensure the efficacy of data integration and the accuracy of analysis results. This may include data cleansing, standardization, and a unified analysis workflow to ensure that data obtained from different databases can be accurately and effectively combined for analysis."
  },
  {
    "objectID": "intro.html#ucsc-xena-data-download-pipeline",
    "href": "intro.html#ucsc-xena-data-download-pipeline",
    "title": "1  Data Source and Introduction",
    "section": "2.1 UCSC Xena Data Download pipeline：",
    "text": "2.1 UCSC Xena Data Download pipeline：\n\n\nLog in to the official website: http://xena.ucsc.edu/\nClick “Launch Xena” to enter the main interface: https://xenabrowser.net/\nClick “DATA SETS” to enter the dataset interface: https://xenabrowser.net/datapages/\nTCGA and GTEX Data Download:\n\nGDC TCGA Breast Cancer (BRCA) (20 datasets)\n\nHTSeq - Counts (n=1,217) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=1,284) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=1,260) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGDC TCGA Melanoma (SKCM) (14 datasets)\n\nHTSeq - Counts (n=472) GDC Hub\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nPhenotype (n=477) GDC Hub\n\ndownload (Download link, copyable)\n\nsurvival data (n=463) GDC Hub\n\ndownload (Download link, copyable)\n\n\nGTEX\n\nTOIL RSEM expected_count (n=7,845) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)\nID/Gene Mapping (Download link, copyable)\n\nGTEX phenotype (n=9,783) UCSC Toil RNA-seq Recompute\n\ndownload (Download link, copyable)"
  },
  {
    "objectID": "intro.html#data-type",
    "href": "intro.html#data-type",
    "title": "1  Data Source and Introduction",
    "section": "2.2 Data Type",
    "text": "2.2 Data Type\n\n2.2.1 count\nIn the context of RNA-seq data analysis, “Count” is an important concept. It represents the number of times each gene or transcript is measured in an RNA-seq experiment. Typically, these counts are obtained through sequencing machines, which measure the number of fragments associated with each gene or transcript, also known as “reads count” or “fragment count,” which indicates how many times each gene or transcript is covered or mapped in the sequencing data. These count data serve as the starting point for RNA-seq data analysis, providing raw information about the expression of genes or transcripts in different samples.\n\n2.2.1.1 Use Cases:\n\nGene Expression Analysis:\n\n\nCount data can be used to compare the relative expression levels of different genes. By tallying the counts for each gene, we can determine which genes are expressed more or less in various samples, identifying key genes.\n\n\nDifferential Expression Analysis:\n\n\nDifferential expression analysis aims to study changes in gene expression levels between different conditions or groups. In this context, count data is employed to compare gene expression levels under different conditions, often requiring statistical models to identify genes with significant differences.\n\n\nClustering Analysis:\n\n\nCount data can also be used for clustering analysis to identify groups of genes or samples with similar expression patterns. Through clustering analysis, genes with similar expression patterns can be grouped together.\n\n\nGene Annotation:\n\n\nCount data helps determine which genes or transcripts have evidence of measurement in the sequencing data, which is crucial for gene annotation.\n\n\n\n2.2.1.2 Advantages:\n\nIntuitiveness:\n\n\nCount data is obtained directly from RNA-seq experiments, providing an intuitive and straightforward representation of gene expression.\n\n\nFlexibility:\n\n\nCount data is versatile and applicable to various RNA-seq data analysis tasks, including basic gene expression analysis and more complex differential expression analysis.\n\n\n\n2.2.1.3 Disadvantages:\n\nImpact of Sequencing Depth and Gene Length:\n\n\nCount data is influenced by sequencing depth and gene length, necessitating standardization when comparing expression levels between different samples or genes.\n\n\nZero Inflation:\n\n\nFor lowly expressed genes, count data may exhibit zero inflation, where counts are predominantly zero. Specialized statistical methods are required to address this issue.\n\n\nResource-Intensive:\n\n\nHandling raw count data can demand significant computational resources and storage space, particularly for large-scale RNA-seq datasets.\n\nIn summary, count data plays a pivotal role in RNA-seq data analysis but typically requires further standardization and analysis to derive meaningful results. It is suitable for use with RNA-seq data types, particularly for gene expression analysis and differential expression analysis.\n\n\n\n2.2.2 RPKM\nRPKM (Reads Per Kilobase of transcript per Million mapped reads) is a method used for quantifying gene expression. This technique overcomes two major barriers: the differences in sequencing depth between samples and the comparison of genes of different lengths. Below is a deeper analysis of the concept, calculation, and application of RPKM, as well as some of its limitations.\n\n2.2.2.1 Principle and Calculation of RPKM:\n\nPrinciple:\n\n\nThe RPKM method corrects the read data in sequencing experiments, making it unaffected by sequencing depth and gene length differences, thereby allowing for a more accurate comparison of gene expression levels under different conditions.\n\n\nCalculation Formula: \\[\nRPKM = \\frac{10^9 \\times C}{N \\times L}\n\\]\nWhere:\n\n\nC is the read count for a specific gene.\nN is the total number of mapped reads in the sequencing experiment.\nL is the transcript length (gene length in base pairs).\nThe \\(\\boldsymbol{10^9}\\) in the formula is a standardization factor used to adjust the units, making the results more comprehensible.\n\n\n\n2.2.2.2 Application Scenarios:\n\nTranscriptomic Studies:\n\n\nIn transcriptome sequencing (RNA-seq), researchers often use RPKM to quantify gene expression, especially when comparing samples from different species, different tissues, or under different treatment conditions.\n\n\nQuantitative Studies of Gene Expression:\n\n\nRPKM provides a way to standardize gene expression data, allowing data obtained from different experiments or under different conditions to be compared.\n\n\n\n\n2.2.3 Advantages:\n\nCorrection for Gene Length:\n\n\nRPKM takes into account the length of the genes, allowing for a fair comparison of expression levels between long and short genes, resolving the issue of read count bias. - Normalization for Sequencing Depth:\n\n\nBy standardizing the total mapped reads, RPKM allows researchers to compare data from different sequencing experiments.\n\n\n2.2.3.1 Challenges:\n\nBias in Low-Abundance Transcripts:\n\n\nRPKM may overestimate the expression levels for genes with low expression because their expression could be amplified due to statistical fluctuations or limitations in sequencing depth.\n\n\nNo Correction for Technical Variations:\n\n\nRPKM does not correct for technical biases that may occur during library preparation or sequencing, and additional statistical methods may be required to correct these biases.\n\n\nNot Suitable for Transcript Diversity:\n\n\nIf a gene has multiple isoforms, RPKM calculation may not reflect the true expression status of each transcript variant.\n\nTherefore, while RPKM is an important tool in RNA-seq data analysis, researchers need to consider its limitations when using it and consider employing other complementary methods, such as TPM (Transcripts Per Million) or more advanced quantification methods like model-based methods (e.g., DESeq2 or edgeR), which can handle differences and variations in data under different samples and conditions more effectively.\n\n\n\n2.2.4 FPKM\nFPKM (Fragments Per Kilobase of transcript, per Million mapped fragments) is an enhancement over RPKM, accounting for the number of sequenced fragments instead of just read counts. This modification is crucial, particularly when a single read might encompass multiple fragments due to events like “split reads” or “spliced reads” in sequencing data.\n\n2.2.4.1 FPKM Calculation:\n\nThe formula for calculating FPKM is: \\[\nFPKM = \\frac{\\text{Number of fragments mapped to a gene}}{(\\frac{\\text{Total mapped fragments}}{1,000,000}) \\times (\\frac{\\text{Length of the gene}}{1,000})}\n\\]\nWhere:\n\n\n“Fragment count of gene” refers to the number of fragments for a specific gene.\n“Gene length in kilobases” is the measurement of the gene length, using kilobases (thousands of base pairs) as the unit.\n“Total mapped fragments in millions” represents the summation of all fragments aligned with the reference genome, expressed in millions.\n\n\n\n2.2.4.2 Suitability:\nFPKM is utilized in situations similar to RPKM, primarily in RNA-seq data analysis, especially when comparing expression levels across genes or between different samples. FPKM allows a more equitable comparison of gene expression by taking into account both gene length and sequencing depth.\n\n\n2.2.4.3 Advantages:\n\nRecognizes gene length, making it suitable for comparing expression levels across genes of diverse lengths.By normalizing per million mapped fragments, FPKM enables more fair comparisons between different samples.\n\n\n\n2.2.4.4 Disadvantages:\n\nIt may misrepresent low-abundance genes, as the total number of mapped fragments in the denominator could lead to inflated FPKM values for these genes.It doesn’t account for potential biases, such as discrepancies in sequencing depth, necessitating further adjustments.\n\n\n\n2.2.4.5 RPKM vs. FPKM:\nThough they appear similar, the necessity for FPKM in addition to RPKM comes from their unique applications and methods of calculation.\n\nDifferences:\nCalculation Basis:\n\n\nWhile RPKM normalizes gene expression levels based on read counts, gene length, and total reads, FPKM does so using fragment counts. This approach is essential for instances where a single read may correspond to multiple fragments.\n\n\nReads vs. Fragments:\n\n\nRPKM, the earlier introduced method, accounts for read counts. FPKM, an advancement over RPKM, considers fragment counts, which is vital for scenarios involving “split reads” or “spliced reads.”\n\n\nNomenclature:\n\n\nRPKM (Reads Per Kilobase of transcript, per Million mapped reads) emphasizes normalization using read counts, whereas FPKM highlights normalization based on fragment counts.\n\n\n\n2.2.4.6 Why FPKM?\n\n\nRPKM is tailored for single-end sequencing, whereas FPKM is more applicable for paired-end RNA-seq because it takes into account that two reads can map to a single fragment, thus avoiding duplication in counting.\nFPKM is generally preferred over RPKM as it offers more precision by including fragment counts, which is particularly important for genes undergoing splicing events.\n\n\n\n\n2.2.4.7 Choosing Between RPKM and FPKM:\nWhile FPKM is generally a better choice due to its enhanced accuracy, the advent of more modern methods like TPM (Transcripts Per Million) has overshadowed both RPKM and FPKM in RNA-seq data analysis. TPM normalizes expression levels based on every million mapped transcripts and is not influenced by gene length or sequencing depth, providing a more reliable reflection of relative expression levels.\n\n\n\n2.2.5 TPM\nTPM (Transcripts Per Million) is an accurate method for measuring gene expression levels, capable of eliminating the effects of sequencing depth and transcript length differences between various samples.\nTo calculate TPM, we first need to obtain the normalized read counts for each transcript, which are then standardized per million transcripts. The steps are as follows:\nCalculate the read counts for each transcript, considering the effective length of the transcript (i.e., excluding the length of non-coding regions).\nCompute the ratio of each transcript’s read count to its effective length, then multiply this ratio by a normalization factor to enable comparisons between samples.\n\n2.2.5.1 TPM calculation formula is as follows:\n\\[\nTPM_i = \\left( \\frac{x_i}{l_i} \\right) \\left( \\frac{1}{\\sum_j \\frac{x_j}{l_j}} \\right) 10^6\n\\]\n\n\n2.2.5.2 Where:\n\n\\(\\boldsymbol{x_i}\\) represents the read count of a specific transcript.\n\\(\\boldsymbol{l_i}\\) is the effective length of the transcript (in kilobases).\nSubscripts \\(\\boldsymbol{i}\\) and \\(\\boldsymbol{j}\\) denote different transcripts.\n\\(\\boldsymbol{\\sum_j \\frac{x_j}{l_j}}\\) is the sum of all transcript read counts ratios to their effective lengths.\n\n\n\n2.2.5.3 The main differences between TPM and RPKM/FPKM:\n\nCalculation method:\n\n\nWith TPM, the expression level of each transcript is first normalized to the length of the transcript, then standardized to the total transcript expression in the sample. In contrast, RPKM/FPKM directly utilize the read counts of transcripts or fragments, normalizing based on transcript length and total read counts.\n\n\nNormalization target:\n\n\nAfter calculating TPM, the total of the TPM values for all transcripts will be 1,000,000, facilitating comparisons between different samples. The total for RPKM/FPKM is not consistent, as they are based on read counts.\n\n\nImpact of gene length:\n\n\nTPM normalizes the effect of gene length on expression level calculations by considering transcript length, making comparisons between transcripts of varying lengths more equitable. Although RPKM/FPKM also standardize based on length, they do not entirely eliminate the influence of gene length when comparing between samples.\n\n\n\n2.2.5.4 The preference for TPM is primarily based on the following reasons:\n\nAccuracy:\n\n\nTPM more accurately reflects the actual expression levels of transcripts, without biases due to differences in sequencing depth or gene length between samples.\n\n\nComparability:\n\n\nTPM values, after standardization, allow for direct comparisons of transcript expression levels between different samples and experiments.\n\n\nUniversality:\n\n\nThe TPM calculation method is suitable for various transcriptomic studies, including gene expression quantification, differential expression analysis, and more.\n\nIn summary, while RPKM/FPKM remain useful in certain contexts, TPM is more widely accepted and utilized in modern transcriptomic analyses due to its accuracy and comparability.\n\n\n\n2.2.6 CPM\nCPM (Counts Per Million) is another prevalent normalization method for assessing gene or transcript expression levels, alongside other techniques such as RPKM, FPKM, and TPM. The principle behind CPM is to standardize the number of times a gene or transcript is measured (counts), allowing for the comparison of expression levels across different genes or transcripts while accounting for the total number of measurements. By normalizing each gene or transcript’s expression levels to per million measurements, CPM minimizes the impact of sequencing depth and differences between samples.\nThe calculation formula for CPM is as follows: \\[\nCPM = \\frac{\\text{Counts of gene/transcript} \\times 10^6}{\\sum (\\text{Counts of all genes/transcripts})}\n\\]\n\n2.2.6.1 Where:\n\n“Counts of gene/transcript” refers to the number of measurements (counts) for a particular gene or transcript.\n“\\(\\boldsymbol{\\sum}\\)” represents the summation symbol, calculating the total counts for all genes or transcripts.\n\n\n\n2.2.6.2 CPM is applicable for:\n\nComparing relative expression levels of different genes or transcripts.\nComparing gene expression levels between samples, particularly when considering variations in sequencing depth and among samples.\n\n\n\n2.2.6.3 Advantages:\n\n\nCPM is a straightforward and intuitive method of normalization, easy to understand and compute.\nIt’s suitable for comparisons between different samples, enabling a fairer assessment of gene expression differences.\n\n\n\n\n2.2.6.4 Disadvantages:\n\n\nCPM may encounter issues with lowly expressed genes because the denominator includes the total counts. For these genes, a smaller denominator might inflate the CPM value, leading to inaccuracies.\nCPM does not account for factors like gene length and sequencing depth, potentially compromising accuracy in certain scenarios.\n\n\nDespite its limitations, CPM stands as a relatively rapid and simplistic normalization technique, fitting for basic RNA-seq data analysis tasks. For instance, during differential analysis, it’s sometimes necessary to eliminate low-expression genes. Here, CPM calculations become relevant, aiding in the exclusion of these genes based on set criteria. For straightforward adjustments of counts, one can utilize the cpm() function within the edgeR package.\n\n\n\n2.2.7 RSEM\nHere, we delve further into the core principles and computational methods of RSEM (RNA-Seq by Expectation-Maximization). RSEM stands as a powerful tool for accurately estimating the expression levels of genes or transcripts. It is particularly proficient in handling RNA sequencing data, resolving issues of multimapping and accounting for sequence mismatches. At the heart of RSEM is the Expectation-Maximization (EM) algorithm, a statistical technique used for estimating the parameters of a probability model, especially in cases where the model involves latent variables that are not directly observable. By maximizing the log-likelihood function of the data, RSEM enables more accurate inference of the relative abundance of transcripts.\n\n2.2.7.1 The computation process of RSEM:\n\n1.E-step (Expectation):\n\n\nUtilizing the current estimates of the parameters, RSEM calculates the expected value of each transcript being sequenced. This step takes into account the sequencing error rate and the multimapping of reads.\n\n\n2.M-step (Maximization):\n\n\nBased on the data generated in the E-step, RSEM updates the parameter estimates to maximize the likelihood of the read data.\n\nGiven the complexity of the calculations and models involved in RSEM, specialized software tools are usually employed for execution. These tools have built-in necessary mathematical models and numerical optimization methods, relieving the user from delving into the intricate details behind them.\n\n\n2.2.7.2 Scope of Application:\n\n\nHigh-precision estimation of transcript abundance, suitable for complex samples with a large number of genes and transcripts, and high heterogeneity.\nQuantitative comparison of gene expression differences between different samples and studying variations between isoforms of transcripts.\n\n\n\n\n2.2.7.3 Advantages:\n\n\nRSEM accurately handles multimapped reads, offering a more precise expression level estimate compared to traditional methods.\nThrough sophisticated statistical models, RSEM fully considers the uncertainties of reads and potential errors during the sequencing process.\n\n\n\n\n2.2.7.4 Disadvantages:\n\n\nThe RSEM calculation process is resource-intensive and time-consuming, potentially unsuitable for large-scale samples or rapid analysis workflows.\nIt requires high-quality data input and is sensitive to low-quality or highly biased data.\n\n\nIn practice, there’s an essential distinction between RSEM’s “expected_count” and the conventional raw “count.” The “expected_count” in RSEM is a statistically estimated floating-point number considering the uncertainties of read assignment, while traditional “count” is merely an integer read count based on raw sequencing data. This difference enables RSEM to provide more in-depth and accurate information on transcript abundance in certain scenarios."
  },
  {
    "objectID": "intro.html#tcga-count-data",
    "href": "intro.html#tcga-count-data",
    "title": "1  Data Source and Introduction",
    "section": "4.1 TCGA Count Data",
    "text": "4.1 TCGA Count Data\n\n\nSTAR Alignment and Counting: The primary counting data in TCGA is generated by STAR, which provides gene ID, unstranded, and stranded counts data following alignment.\nMulti-dimensional Data Collection: TCGA collects many types of data including molecular characterization data for over 20,000 tumor and normal samples, contributing to the count data."
  },
  {
    "objectID": "intro.html#gtex-expected-count-data",
    "href": "intro.html#gtex-expected-count-data",
    "title": "1  Data Source and Introduction",
    "section": "4.2 GTEx Expected Count Data",
    "text": "4.2 GTEx Expected Count Data\n\n\nPipeline Components for RNA-seq Alignment, Quantification: GTEx utilizes a pipeline for RNA-seq alignment, quantification, and quality control among other analysis tasks, which lead to the generation of expected count data.\nAlignment and Expression Quantification: GTEx RNA-seq pipeline involves alignment (STAR), QC (RNA-SeQC), and expression quantification (RSEM & RNA-SeQC) for generating expected count data.\n76-base, Paired-end Illumina TruSeq RNA Protocol: GTEx uses a 76-base, paired-end Illumina TruSeq RNA protocol, averaging around 50 million aligned reads per sample for RNA sequencing."
  },
  {
    "objectID": "summar.html",
    "href": "summar.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "index.html#who-is-this-for",
    "href": "index.html#who-is-this-for",
    "title": "TransProRBook",
    "section": "Who is this for?",
    "text": "Who is this for?\nThis is not a beginner’s introduction to data programming, though you certainly don’t need to be an expert to read it. If you have some familiarity with any dataframe library, most of the examples should make sense, but if you’re familiar with Pandas they’ll make even more sense because all the Polars code is accompanied by the equivalent Pandas code.\nYou don’t need to have read Modern Pandas, though I of course think it’s a great read."
  },
  {
    "objectID": "index.html#why",
    "href": "index.html#why",
    "title": "TransProRBook",
    "section": "Why?",
    "text": "Why?\nThere’s this weird phenomenon where people write data programming code as if they hate themselves. Many of them are academic or quant types who seem to have some complex about being “bad at coding”. Armchair psychology aside, lots of clever folk keep doing really dumb stuff with Pandas, and at some point you have to wonder if the Pandas API is too difficult for its users.\nAt the very least, articles like Minimally Sufficient Pandas make a compelling case for Pandas having too much going on.\nHaving used Pandas a lot, I think Polars is more intuitive and does a better job of having One Obvious Way to do stuff. It’s also much faster at most things, even when you do Pandas the right way.\nHopefully this work shows you how, why and when to prefer Polars."
  },
  {
    "objectID": "index.html#credit",
    "href": "index.html#credit",
    "title": "TransProRBook",
    "section": "Credit",
    "text": "Credit\nThe Pandas examples are mostly lifted from Tom’s articles, with some updates for data that’s no longer available, and some code changes to reflect how Pandas is written in 2023. This isn’t just me being lazy - I want to draw on Pandas examples that quite a lot of people are already familiar with.\nSo credit goes to Tom for the Pandas examples, for most of the data fetching code and for the general structure of the articles. Meanwhile the text content and the Polars examples are from me."
  },
  {
    "objectID": "index.html#running-the-code-yourself",
    "href": "index.html#running-the-code-yourself",
    "title": "TransProRBook",
    "section": "Running the code yourself",
    "text": "Running the code yourself\nYou can install the exact packages that the book uses with the env.yml file:\nmamba env create -f env.yml\nIf you’re not using mamba/conda you can install the following package versions and it should work:\npolars: 0.19.9\npyarrow: 10.0.1\npandas: 2.1.1\nnumpy: 1.23.5\nfsspec: 2022.11.0\nmatplotlib: 3.8.0\nseaborn: 0.13.0\nstatsmodels: 0.14.0\nfilprofiler: 2022.11.0\n\nData\nAll the data fetching code is included, but will eventually break as websites change or shut down. The smaller datasets have been checked in here for posterity."
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "TransProRBook",
    "section": "Contributing",
    "text": "Contributing\nThis book is free and open source, so please do open an issue if you notice a problem!"
  }
]